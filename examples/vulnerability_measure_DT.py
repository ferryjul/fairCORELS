from sklearn.model_selection import train_test_split # version 0.24.1
from faircorels import load_from_csv, FairCorelsClassifier, ConfusionMatrix, Metric # version 1.0
import numpy as np
from sklearn.datasets import fetch_openml
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn import tree
import pandas as pd

sensitive_attr_column = 0
unsensitive_attr_column = 1
max_memory = 4000
verbose = False
datasets = ['adult_income', 'compas']
dataset = datasets[0]
X, y, features, prediction = load_from_csv("./data/%s_fullRules.csv" %dataset)#("./data/adult_full.csv") # Load the dataset

if verbose:
    print("Sensitive attribute is ", features[sensitive_attr_column])
    print("Unsensitive attribute is ", features[unsensitive_attr_column])

# Load data
data = fetch_openml(data_id=1590, as_frame=True)

y_true = (data.target == '>50K') * 1 # label
#sex = data.data['sex'] # sensitive attribute

X_raw = data.data # features
X = X_raw#.drop(labels=['sex'], axis=1)
X = pd.get_dummies(X)

sc = StandardScaler()
X_scaled = sc.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

le = LabelEncoder()
y_true = le.fit_transform(y_true)

if verbose:
    print("Loaded and preprocessed data!")


def target_model_fn():
    """The architecture of the target (victim) model.
    The attack is white-box, hence the attacker is assumed to know this architecture too."""
    # Create the FairCorelsClassifier object
    clf = tree.DecisionTreeClassifier(min_samples_leaf=10) #, max_depth=criterion_value
    return clf

def compute_vulnerability_simpler(adversary, true_y_train, predicted_y_train, true_y_test, predicted_y_test, sens_vect_train, sens_vect_test, print_infos=False):
    predictions_train = np.asarray([predicted_y_train[i][1] for i in range(len(predicted_y_train))])
    predictions_test = np.asarray([predicted_y_test[i][1] for i in range(len(predicted_y_test))])

    advantage = 0
    if true_y_train.shape[0] != predicted_y_train.shape[0] or true_y_test.shape[0] != predicted_y_test.shape[0]:
        print("Shape errors")
        return -1
    # All existing true labels
    y_list = np.unique(np.union1d(true_y_train, true_y_test))
    # All existing confidence scores
    y_pred_list = np.unique(np.union1d(predicted_y_train, predicted_y_test))
    # All existing z values
    z_list =  np.unique(np.union1d(sens_vect_train, sens_vect_test))
    if verbose:
        print(z_list)
    # Probas y
    probas_y = dict()
    for y in y_list:
        probas_y[y] = (np.sum(true_y_train == y)+np.sum(true_y_test == y))/(true_y_train.shape[0]+true_y_test.shape[0])
    if print_infos:
        print(probas_y)
    # Probas z
    probas_z = dict()
    probas_z['sens']=(np.sum(sens_vect_train == 1)+np.sum(sens_vect_test == 1))/(true_y_train.shape[0]+true_y_test.shape[0])
    probas_z['unsens']=(np.sum(unsens_vect_train == 1)+np.sum(unsens_vect_test == 1))/(true_y_train.shape[0]+true_y_test.shape[0])

    # Probas z intersect y = proba z * proba y sachant z
    probas_y_z = dict()
    probas_y_z['sens']=dict()
    probas_y_z['unsens']=dict()
    for y in y_list:
        nb_y_z_train = len(np.intersect1d(np.where(true_y_train == y), np.where(sens_vect_train == 1)))
        nb_y_z_test = len(np.intersect1d(np.where(true_y_test == y), np.where(sens_vect_test == 1)))
        probas_y_z['sens'][y]=(nb_y_z_train+nb_y_z_test)/(true_y_train.shape[0]+true_y_test.shape[0])
        nb_y_z_train = len(np.intersect1d(np.where(true_y_train == y), np.where(unsens_vect_train == 1)))
        nb_y_z_test = len(np.intersect1d(np.where(true_y_test == y), np.where(unsens_vect_test == 1)))
        probas_y_z['unsens'][y]=(nb_y_z_train+nb_y_z_test)/(true_y_train.shape[0]+true_y_test.shape[0])
    if print_infos:
        print(probas_y_z)

    if adversary == 'regular':
        for y in y_list:
            tau_y = 0
            for y_pred in y_pred_list:
                nb_y_pred_y_train = len(np.intersect1d(np.where(true_y_train == y), np.where(predictions_train == y_pred)))
                tot_y_train = np.sum(true_y_train == y)
                nb_y_pred_y_test = len(np.intersect1d(np.where(true_y_test == y), np.where(predictions_test == y_pred)))
                tot_y_test = np.sum(true_y_test == y)
                proba_y_pred_y_train=nb_y_pred_y_train/tot_y_train
                proba_y_pred_y_test=nb_y_pred_y_test/tot_y_test
                probas_diff=(proba_y_pred_y_train)-(proba_y_pred_y_test)
                tau_y+=abs(probas_diff)
            tau_y *= (1/2)
            if print_infos:
                print(">> Distributional Overfitting distance for class ", y , " : ", tau_y)
            advantage+=probas_y[y]*tau_y

    elif adversary == 'discriminating':
       for y in y_list:
            for z in ['sens', 'unsens']:
                tau_z_y = 0
                for y_pred in y_pred_list:
                    if z == 'sens':
                        nb_y_pred_y_train = len(np.intersect1d(np.intersect1d(np.where(true_y_train == y), np.where(predictions_train == y_pred)),np.where(sens_vect_train == 1)))
                        tot_y_train = len(np.intersect1d(np.where(true_y_train == y), np.where(sens_vect_train == 1)))
                        nb_y_pred_y_test = len(np.intersect1d(np.intersect1d(np.where(true_y_test == y), np.where(predictions_test == y_pred)),np.where(sens_vect_test == 1)))
                        tot_y_test = len(np.intersect1d(np.where(true_y_test == y), np.where(sens_vect_test == 1)))
                    elif z == 'unsens':
                        nb_y_pred_y_train = len(np.intersect1d(np.intersect1d(np.where(true_y_train == y), np.where(predictions_train == y_pred)),np.where(unsens_vect_train == 1)))
                        tot_y_train = len(np.intersect1d(np.where(true_y_train == y), np.where(unsens_vect_train == 1)))
                        nb_y_pred_y_test = len(np.intersect1d(np.intersect1d(np.where(true_y_test == y), np.where(predictions_test == y_pred)),np.where(unsens_vect_test == 1)))
                        tot_y_test = len(np.intersect1d(np.where(true_y_test == y), np.where(unsens_vect_test == 1)))
                    else:
                        print("Unexpected")
                    proba_y_pred_y_train=nb_y_pred_y_train/tot_y_train
                    proba_y_pred_y_test=nb_y_pred_y_test/tot_y_test
                    probas_diff=(proba_y_pred_y_train)-(proba_y_pred_y_test)
                    tau_z_y+=abs(probas_diff)
                tau_z_y *= (1/2)
                if print_infos:
                    print(">> Distributional Overfitting distance for class ", y , " and group ", z, " : ", tau_z_y)
                advantage+=probas_y_z[z][y]*tau_z_y
    else:
        print("Unknown mode ", adversary)
    return 0.5 + 0.5*advantage # overall vulnerability value for regular adversary

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_true, test_size=0.5, random_state=42)
if verbose:
    print("Using ", X_train.shape[0], " examples for training set, ", X_test.shape[0], " examples for test set.")

# Train the target model.
if verbose:
    print("Training the target model...")
target_model = target_model_fn()
            
target_model.fit(X_train, y_train, memory_limit=max_memory)

if verbose:
    print("Trained DT (target model):")
import matplotlib.pyplot as plt
fig, axes = plt.subplots(nrows=1,ncols=1,figsize=(4,4),dpi=300)
tree.plot_tree(target_model, filled=True)
#fig.savefig("./decisiontree.png")

#print('train preds are:', np.unique(y_train_pred))
#print('test preds are:', np.unique(y_test_pred))
adversaries = ['regular', 'discriminating']
predict_modes = ['label_only', 'probas']
for adversary in adversaries:
    for predict_mode in predict_modes:
        if predict_mode == 'label_only':
            y_train_pred = target_model.predict(X_train)
            y_test_pred = target_model.predict(X_test)
        else:
            y_train_pred = target_model.predict_proba(X_train)
            y_test_pred = target_model.predict_proba(X_test)
        print("----- Mode %s (%s attacker)------" %(predict_mode, adversary))
        vuln = compute_vulnerability_simpler(adversary, y_train, y_train_pred, y_test, y_test_pred, X_train['sex'], X_test['sex'], print_infos=True)
        print("Overall vulnerability is ", vuln)
        print("--------------------")